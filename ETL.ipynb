{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"log_file.txt\" \n",
    "target_file = \"transformed_data.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_name):\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    return df\n",
    "\n",
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe \n",
    "\n",
    "\n",
    "def extract_from_txt(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe \n",
    "\n",
    "\n",
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file, transformed_data): \n",
    "    transformed_data.to_csv(target_file) \n",
    "    \n",
    "    \n",
    "    \n",
    "def log_progress(message): \n",
    "    '''Write log messages with time stamp to a file''' \n",
    "    with open(log_file, 'a+') as f: \n",
    "        f.write(\"{}: {}\\n\".format(datetime.now(), message))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "     name  height  weight      0       1       2\n",
      "0     NaN     NaN     NaN   name  height  weight\n",
      "1     NaN     NaN     NaN   alex   65.78  112.99\n",
      "2     NaN     NaN     NaN   ajay   71.52  136.49\n",
      "3     NaN     NaN     NaN  alice   69.40  153.03\n",
      "4     NaN     NaN     NaN   ravi   68.22  142.34\n",
      "5     NaN     NaN     NaN    joe   67.79  144.30\n",
      "6     NaN     NaN     NaN   name  height  weight\n",
      "7     NaN     NaN     NaN   alex   65.78  112.99\n",
      "8     NaN     NaN     NaN   ajay   71.52  136.49\n",
      "9     NaN     NaN     NaN  alice   69.40  153.03\n",
      "10    NaN     NaN     NaN   ravi   68.22  142.34\n",
      "11    NaN     NaN     NaN    joe   67.79  144.30\n",
      "12    NaN     NaN     NaN   name  height  weight\n",
      "13    NaN     NaN     NaN   alex   65.78  112.99\n",
      "14    NaN     NaN     NaN   ajay   71.52  136.49\n",
      "15    NaN     NaN     NaN  alice   69.40  153.03\n",
      "16    NaN     NaN     NaN   ravi   68.22  142.34\n",
      "17    NaN     NaN     NaN    joe   67.79  144.30\n",
      "18   jack    1.74   55.93    NaN     NaN     NaN\n",
      "19    tom    1.77   64.18    NaN     NaN     NaN\n",
      "20  tracy    1.78   61.90    NaN     NaN     NaN\n",
      "21   john    1.72   50.97    NaN     NaN     NaN\n",
      "22   jack    1.74   55.93    NaN     NaN     NaN\n",
      "23    tom    1.77   64.18    NaN     NaN     NaN\n",
      "24  tracy    1.78   61.90    NaN     NaN     NaN\n",
      "25   john    1.72   50.97    NaN     NaN     NaN\n",
      "26   jack    1.74   55.93    NaN     NaN     NaN\n",
      "27    tom    1.77   64.18    NaN     NaN     NaN\n",
      "28  tracy    1.78   61.90    NaN     NaN     NaN\n",
      "29   john    1.72   50.97    NaN     NaN     NaN\n",
      "30  simon    1.72   50.97    NaN     NaN     NaN\n",
      "31  jacob    1.70   54.73    NaN     NaN     NaN\n",
      "32  cindy    1.69   57.81    NaN     NaN     NaN\n",
      "33   ivan    1.72   51.77    NaN     NaN     NaN\n",
      "34  simon    1.72   50.97    NaN     NaN     NaN\n",
      "35  jacob    1.70   54.73    NaN     NaN     NaN\n",
      "36  cindy    1.69   57.81    NaN     NaN     NaN\n",
      "37   ivan    1.72   51.77    NaN     NaN     NaN\n",
      "38  simon    1.72   50.97    NaN     NaN     NaN\n",
      "39  jacob    1.70   54.73    NaN     NaN     NaN\n",
      "40  cindy    1.69   57.81    NaN     NaN     NaN\n",
      "41   ivan    1.72   51.77    NaN     NaN     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saaag\\AppData\\Local\\Temp\\ipykernel_2092\\1266167729.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
      "C:\\Users\\saaag\\AppData\\Local\\Temp\\ipykernel_2092\\1266167729.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\saaag\\AppData\\Local\\Temp\\ipykernel_2092\\1266167729.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\saaag\\AppData\\Local\\Temp\\ipykernel_2092\\1266167729.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract() \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
